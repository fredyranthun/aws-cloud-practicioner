# Amazon S3

## Introduction

- Amazon S3 is one of the main building blocks of AWS
- "Infinitely scaling" storage
- Many websites use AWS S3 as a backbone
- Many AWS services use AWS S3 as an integration as well

## Use cases

- Backup and storage
- Disaster Recovery
- Archive
- Hybrid Cloud storage
- Application Hosting
- Media Hosting
- Data lakes and big data analytics
- Software delivery
- Static website

## Buckets

- Top level directories
- files in the Buckets are called objects
- Buckets must have a globally unique name (acroos all regions all accounts)
- Buckets are defined at a region level
- S3 looks like a global service but buckets are created in a region
- Naming convention
  - no uppercase, no underscore
  - 3-63 characters long
  - Not an IP
  - Start with lowercase letter or number
  - Must not start with prefix xn--
  - Must not end with the suffix -s3alias

## Objects

- Objects (files) have a key
- The key is the full path:
  - s3://my-bucket/my-file.txt
- The key is composed of prefix + object name
  - s3://my-bucket/my_folder/another_folder/my_file.txt
  - prefix are the folders "my_folder/another_folder/"
  - object name is "my_file.txt"
- There is no concept of "directories" within buckets, despite UI trick you to think otherwise
- There are just keys with long names which contain slashes "/"
- Object values are the content of the body
  - Max. object size is 5TB (5000GB)
  - If uploading more than 5GB, must use "multi-part upload"
- Metadata: (list of key/value pairs - system or user metadata)
- Version ID - if enabled versioning
- Objects will not be accessible from public url if the bucket policy does not allow it.

## S3 Security

### User Based

- IAM Policies - which API calls should be allowed for a specific user from IAM

### Resource Based

- Bucket policies - bucket wide rules from S3 console - allows cross account
- Object Access Control List (ACL) - finer grain (can be disabled)
- Bucket Access Control List (ACL) - less common (can be disabled)
- IAM principal can access an S3 object if

  - the user IAM permissions ALLOW it OR the resource policy ALLOWS ir
  - AND there is no explicit DENY

- Encryption - extra layer of security

## S3 Bucket Policies

- Json based Policies
  - Resources: buckets and objects
  - Effect: Allow/Deny
  - Actions: Set of API to allow or deny
  - Principal - account or user to apply the policy to
- Can be used to:
  - grant public access to the bucket
  - Force objects to be encrypted at upload
  - grant access to another account (Cross account)

## Bucket Settings for block public access

- extra layer of security
- prevent company data leaks
- if you know your bucket should never be public, leave these on
- can be set at the account level

## Static website Hosting

- S3 can host websites and have them accessible on the internet
- Options of url:
  - http://bucket-name.s3-website-aws-region.amazonaws.com
  - http://bucket-name.s3-website.aws-region.amazonaws.com
- The bucket must allows public reads
- enable static website hosting - should specify a index.html

## S3 Versioning

- enabled at bucket level
- same key overwrite will change to version: 1, 2, 3...
- It is best practice to version
  - Protect against unintended deletes
  - Easy roll back to previous version
- Files previous version enabling will have version null
- suspending versioning does not delete the previous versions
- when you delete a file you create a delete marker, and that file can be restored later

## AWS S3 Replication (CRR and SRR)

- Must enable versioning in source and destination buckets
- CRR - Cross Region Replication
- SRR - Same Region Replication
- Buckets can be in different AWS accounts
- Copying is asynchronous
- Must give proper IAM permissions to S3
- Use Cases:
  - CRR - compliance, lower lattency access, replication across accounts
  - SRR - log aggregation. live replication between production and test accounts

## AWS S3 Storage Classes

- S3 Standard - General Purpose
- S3 Standard-Infrequent Access (IA)
- S3 One Zone-Infrequent Access (IA)
- S3 Glacier Instant Retrieval
- S3 Glacier Flexible Retrieval
- S3 Glacier Deep Archive
- S3 Glacier Intelligent Tiering

- You can move between classes manually or using S3 Lifecycle configurations
- The storage class ir configured per Object

### S3 Durability and Availability

- High Durability - 11 9's - 99.999999999% of objects across multiple AZ
- If you store 10,000,000 objects with S3 you can average expect to incur a loss of a single object once every 10,000 years
- Same for all storage classes

- Availability
  - how readily available a service is
  - varies depending on storage class
  - Example: S3 standard has 99.99% availability - not available 53 minutes a year

#### S3 Standard

- 99.99% availability
- frequently accessed data
- low latency and high throughput
- sustain 2 concurrent facility failures
- Use cases: Bid data analytics, mobile and gaming application, content distribution...

#### S3 Infrequent Access

- Lower cost
- less frequent accessed
- Standard Infrequent Access
  - 99.9% availability
  - Use cases: disaster recoveries and backups
- One Zone Infrequent Access
  - High durability in a single AZ - the data is lost when AZ is destroyed
  - 99.5% availability
  - Use Cases: Storing secondary backup copies of on-premise data, or data you can recreate

#### S3 Glacier

- Low cost storage archiving / backup
- Pricing: price per storage + object retrieval cost
- Glacier Instant Retrieval
  - Millisecond retrieval, great for data accessed once a quarter
  - minimun storage of 90 days
- Glacier Flexible Retrieval
  - Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) - free
  - Minimum storage of 90 days
- Glacier Deep Archive
  - Standard (12 hours), Bulk (48 hours)
  - minimun storate of 180 days

#### S3 Intelligent Tier

- small monthly monitoring and auto-tiering fee
- moves objects automatically between access tiers based on usage
- there are no retrieval charges in S3 Intelligent Tiering
- Frequent access tier (automatic): default tier
- Infrequent access tier (automatic): objects not accessed for 30 days
- Archive instant Access tier (automatic): objects not accessed for 90 days
- Archive Access Tier (optional): config from 90 to 700+ days
- Depp Archive Acces Ties (optional): config from 180 to 700+ days

## S3 Encryption

- Server Side Encryption
  - The object will be encrypted
  - The server will do the encryption after receiving it
- Client Side Encryption
  - The user will encrypts the file before upload it
- By default, server side encryption is always on

## IAM Access Analyzer

- Ensures tha only intended people have access to your S3 buckets
- Evaluates S3 bucket policies, S3 ACLs, S3 Access Point Policies
- Powered by IAM Access Analyzer

## Shared Responsibility model

- AWS
  - Infrastructure
  - configuration and vulnerability analysis
  - compliance validation
- You
  - S3 Versioning
  - Correct S3 Bucket Policy
  - S3 Replication setup
  - Logging and monitoring
  - S3 Storage Class
  - Data Encryption at rest and in transit

# AWS Snow Family

- Highly secure, portable devices
- Collect and process data at the edge and migrate data into and out of AWS
- Data Migration
  - Snowcone
  - Snowball Edge
  - Snowmobile
- Edge Computing
  - Snowcone
  - Snowball Edge
- Data Migration - difficult to migrate large amounts of data to and from cloud
- Snow Family - offline devices to perform data migration
- transfer of data via physical way (not network)

## Snow Family for Data Migrations

### Snowcone

- 8 TB HDD and 14 TB SSD
- Migration Size until 24 TB, online and offline
- DataSync Agent: pre installed

### Snowball Edge Storage Optimized

- 80 TB - 210 TB
- Migration size: Up to petabytes, offline

### Snowmobile

- Bigger than 100 PB
- Up to exabytes, offline

### Usage Process

- Request Snowball devices from the AWS Console for delivery
- install snowball client / AWS OpsHubs on your servers
- Connect the snowball to your servers and copy files using the client
- Ship back the device when you are done
- Data will be loaded into an S3 bucket
- Snowball is completely wiped

## Edge Computing

- Process data while it is being created on edge location
- Edge location are places with limited internet access and/or limited access to computing power
- We setup a snowball edge / snowcone device to do edge computing
- Use Cases:
  - preprocess data
  - machine learning at the edge
  - transcoding media streams
- eventually (if need be) we can ship back the device to AWS (for transfering data for example)

### Snowcone and Snowcone SSD

- 2 cpus and 4 GB of memory, wired or wireless access
- USB-C

### Snowball Edge - Compute Optimized

- 104 vCPUs, 416 GB of RAM
- Optional GPU
- 28 TB NVMe or 42 TB HDD
- Storage clustering available

### Snowball Edge - Stoorage Optimized

- up to 40 CPUs, 80 GB of RAM, 80 TB of storage
- up to 104 CPUs, 416 GB of RAM, 210 TB NVMe storage

- All of them can run EC2 instances and AWS Lambda
- Long term deployment options: 1 and 3 years discount

## AWS OpsHub

- You can install on your computer / laptop to manage Snow Family Device
- manage all the functionalities of the devices

## Snowball Edge Pricing

- pay for device usage and data trasfer out of AWS
- on demand: pay per day per additional day

# Hybrid Cloud for Storage

- This can be due to:
- long cloud migrations
- Security requirement
- Compliance requirement
- IT Strategy
- to expose S3 data on premise you need to use AWS Storage Gateway
- it is a Bridge between on-premise data and cloud data in S3

- Types of storage in cloud
  - Volumes: EBS and EC2 Instance Store
  - File: AWS EFS
  - Object: S3 and S3 Glacier

# Summary

- Buckets and Objects
- S3 Security - IAM Policy, S3 Bucket Policy, S3 Encrytion
- Enable Static Websites
- S3 Versioning
- S3 Replication
- S3 Storage Classes
- Snow Family
- OpsHub - desktop application to manage Snow Family Devices
- AWS Storage Gateway
